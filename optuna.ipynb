{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#На данном этапе необходимо иметь готовый X_train, Y_train \ndata_train = lgb.Dataset(X_train, label=Y_train)\nrkf = StratifiedKFold(n_splits=4, random_state=48, shuffle = True)\n\n#training rounds и best score понадобится чтобы определить оптимальное число num_boost_round\nbest_score = 999\ntraining_rounds = 10000\n\ndef objective(trial):\n    global best_score, training_rounds\n    param = {\n        \"objective\": \"multiclass\",\n        \"metric\": \"multi_logloss\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"num_classes\": 7,\n        \"seed\": 48,\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 0, 15),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 120),\n        'feature_pre_filter': False\n    }\n    \n    lgbcv = lgb.cv(param,\n                   data_train,\n                   folds=rkf,\n                   verbose_eval=False,\n                   categorical_feature=cat_features,\n                   early_stopping_rounds=300,                   \n                   num_boost_round=15000,                    \n                   callbacks=[lgb.reset_parameter(learning_rate = [0.005]*300 + [0.001]*7300 + [0.0005]*7400) ]\n                  )\n    \n    cv_score = lgbcv['multi_logloss-mean'][-1]\n    #Если cv_score является лучшим, то запоминаем число training_rounds\n    if cv_score<best_score:\n        training_rounds = len( list(lgbcv.values())[0] )\n        best_score = cv_score\n    \n    return cv_score\n\nstudy = optuna.create_study(direction='minimize')  \nstudy.optimize(objective, timeout=27000) ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}